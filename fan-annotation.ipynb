{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "import itertools\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "sp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match_filename_6gram = 'match-6gram-20170614.csv'\n",
    "match_filename_10gram = 'match-20k-10gram-wordlevel-20170406.csv'\n",
    "match_filename = match_filename_6gram\n",
    "script_filename = '../../../../original-scripts/force-awakens/force-awakens-markup.txt'\n",
    "fan_filename_base = '7382338.txt'  # '6165466.txt'\n",
    "fan_directory = '../../../../fan-works/force-awakens-fullset/english-plaintext/'\n",
    "browser_directory = '../../../../analysis/reuse/force-awakens-parallel-browsers/'\n",
    "distance_scale = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html_wrapper = \"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>{}</title>\n",
    "    <style>\n",
    "      #content, html, body {{\n",
    "          height: 98%;\n",
    "      }}\n",
    "      #script {{\n",
    "          float: left;\n",
    "          width: 50%;\n",
    "          height: 100%;\n",
    "          overflow: scroll;\n",
    "      }}\n",
    "      #fanwork {{\n",
    "          float: left;\n",
    "          width: 50%;\n",
    "          height: 100%;\n",
    "          overflow: scroll;\n",
    "      }}\n",
    "      .match.intensity-0 {{\n",
    "          background-color: rgba(16, 96, 255, 0.65);\n",
    "      }}\n",
    "      .match.intensity-1 {{\n",
    "          background-color: rgba(16, 96, 255, 0.55);\n",
    "      }}\n",
    "      .match.intensity-2 {{\n",
    "          background-color: rgba(16, 96, 255, 0.45);\n",
    "      }}\n",
    "      .match.intensity-3 {{\n",
    "          background-color: rgba(16, 96, 255, 0.35);\n",
    "      }}\n",
    "      .match.intensity-4 {{\n",
    "          background-color: rgba(16, 96, 255, 0.25);\n",
    "      }}\n",
    "      .match {{\n",
    "          background-color: rgba(16, 96, 255, 0.15);\n",
    "      }}\n",
    "      .match.selected {{\n",
    "          background-color: rgba(224, 0, 0, 0.45);\n",
    "          /* color: rgba(0, 0, 0, 1.0); */\n",
    "      }}\n",
    "    </style>\n",
    "    <script type=\"text/javascript\">\n",
    "      document.addEventListener('DOMContentLoaded', function() {{\n",
    "        function align() {{\n",
    "        \n",
    "          // Class names encode word-level links; the class\n",
    "          // is just the attribute ID of the linked word!\n",
    "          var mid = this.getAttribute('class').match(/(fan|script)-match-\\d+/g);\n",
    "          \n",
    "          // If a correctly formatted link ID was found...\n",
    "          if (mid.length > 0) {{\n",
    "            mid = mid[0];\n",
    "            var scriptEl, fanEl, offset;\n",
    "            \n",
    "            var scriptContainer = document.getElementById('script');\n",
    "            var fanContainer = document.getElementById('fanwork');\n",
    "\n",
    "            // Check whether the link is from fan to script\n",
    "            // or script to fan...\n",
    "            if (mid.includes('script')) {{\n",
    "              fanEl = document.getElementById(this.id);\n",
    "              scriptEl = document.getElementById(mid);\n",
    "              offset = fanEl.offsetTop - fanContainer.scrollTop;\n",
    "              scriptContainer.scrollTop = scriptEl.offsetTop - offset;\n",
    "            }} else {{\n",
    "              scriptEl = document.getElementById(this.id);\n",
    "              fanEl = document.getElementById(mid);\n",
    "              offset = scriptEl.offsetTop - scriptContainer.scrollTop;\n",
    "              fanContainer.scrollTop = fanEl.offsetTop - offset;\n",
    "\n",
    "            }}\n",
    "            \n",
    "            // Reverse iteration ensures that if the collection\n",
    "            // is updated (because the selecting class has been\n",
    "            // removed!) it will not change the order of iteration.\n",
    "            var oldSelected = document.getElementsByClassName('selected');\n",
    "            for (var s = oldSelected.length - 1; s >= 0; s -= 1) {{\n",
    "              oldSelected[s].classList.remove('selected');\n",
    "            }}\n",
    "            \n",
    "            scriptEl.classList.add('selected');\n",
    "            fanEl.classList.add('selected');\n",
    "          }}\n",
    "        }}\n",
    "\n",
    "        var matches = document.getElementsByClassName('match');\n",
    "        for (var m = 0; m < matches.length; m += 1) {{\n",
    "          matches[m].addEventListener('click', align);\n",
    "        }}\n",
    "      }});\n",
    "    </script>\n",
    "  </head>\n",
    "  <body>\n",
    "    <div id=\"content\">\n",
    "      <div id=\"script\">\n",
    "        {}\n",
    "      </div>\n",
    "      <div id=\"fanwork\">\n",
    "        {}\n",
    "      </div>\n",
    "    </div>\n",
    "  <script>\n",
    "  </script>\n",
    "  </body>\n",
    "</html>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_markup_script(filename,\n",
    "                        _line_rex=re.compile('LINE<<(?P<line>[^>]*)>>'),\n",
    "                        _scene_rex=re.compile('SCENE_NUMBER<<(?P<scene>[^>]*)>>'),\n",
    "                        _char_rex=re.compile('CHARACTER_NAME<<(?P<character>[^>]*)>>')):\n",
    "    with open(filename, encoding='utf-8') as ip:\n",
    "        current_scene = None\n",
    "        current_char = None\n",
    "        current_line = None\n",
    "        rows = [['LOWERCASE', 'SPACY_ORTH_ID', 'SCENE', 'CHARACTER']]\n",
    "        for i, line in enumerate(ip):\n",
    "            if _scene_rex.search(line):\n",
    "                current_scene = int(_scene_rex.search(line).group('scene'))\n",
    "            elif _char_rex.search(line):\n",
    "                current_char = _char_rex.search(line).group('character')\n",
    "            elif _line_rex.search(line):\n",
    "                tokens = sp(_line_rex.search(line).group('line'))\n",
    "                for t in tokens:\n",
    "                    # original Spacy lexeme object can be recreated using\n",
    "                    #     spacy.lexeme.Lexeme(sp.vocab, t.orth)\n",
    "                    # where `sp = spacy.load('en')`\n",
    "                    row = [t.lower_, t.lower, current_scene, current_char]\n",
    "                    rows.append(row)\n",
    "    return rows\n",
    "\n",
    "def load_fan_work(base):\n",
    "    if not base.endswith('.txt'):\n",
    "        base += '.txt'\n",
    "    fan_filename = fan_directory + base\n",
    "    with open(fan_filename, encoding='utf-8') as ip:\n",
    "        return sp(ip.read())\n",
    "    \n",
    "def load_matches(match_filename):\n",
    "    with open(match_filename, encoding='utf-8') as ip:\n",
    "        return list(csv.reader(ip))\n",
    "\n",
    "def file_getter(match):\n",
    "    return os.path.split(match[0])[-1]\n",
    "    \n",
    "def file_ix_getter(match):\n",
    "    return (file_getter(match), int(match[1]))\n",
    "    \n",
    "def contig_match_map(matches):\n",
    "    matches = matches[1:]\n",
    "    matches.sort(key=file_ix_getter)\n",
    "    m_groups = itertools.groupby(matches, key=file_getter)\n",
    "    \n",
    "    match_map = {}\n",
    "    for fn, m_group in m_groups:\n",
    "        contig = []\n",
    "        last = -2\n",
    "        for m in m_group:\n",
    "            ix = int(m[1])\n",
    "            if int(ix) != last + 1:\n",
    "                contig.append([m])\n",
    "            else:\n",
    "                contig[-1].append(m)\n",
    "            last = ix\n",
    "    \n",
    "        match_map[fn] = contig\n",
    "\n",
    "    return match_map\n",
    "\n",
    "def contig_match_map_merged(matches, n):\n",
    "    match_map = contig_match_map(matches)\n",
    "    for fn in match_map:\n",
    "        match_map[fn] = [c\n",
    "                         for contig in match_map[fn]\n",
    "                         for c in merge_contig(contig, n)]\n",
    "    return match_map\n",
    "\n",
    "def contig_match_map_merged_no_overlap(matches, n):\n",
    "    match_map = contig_match_map(matches)\n",
    "    for fn in match_map:\n",
    "        match_map[fn] = [merge_contig(contig, n)[0]\n",
    "                         for contig in match_map[fn]]\n",
    "    return match_map\n",
    "    \n",
    "def merge_contig(contig, n):\n",
    "    merged = []\n",
    "    n_matches = 1 + len(contig) - n\n",
    "    for i in range(n_matches):\n",
    "        newmatch = contig[i][:]\n",
    "        fan_ngram = ' '.join(contig[i + j][2] for j in range(n))\n",
    "        script_ngram = ' '.join(contig[i + j][5] for j in range(n))\n",
    "        newmatch[2] = fan_ngram\n",
    "        newmatch[5] = script_ngram\n",
    "        merged.append(newmatch)\n",
    "    return merged\n",
    "\n",
    "def fan_match_html(matches, fan):\n",
    "    match_dict = defaultdict(list)\n",
    "    for m in matches:\n",
    "        match_dict[int(m[1])].append(m)\n",
    "    for i, w in enumerate(fan):\n",
    "        if i in match_dict:\n",
    "            best_match = min(match_dict[i], key=lambda m: float(m[-1]))\n",
    "            match_from = i\n",
    "            match_to = int(best_match[4])\n",
    "            distance = round(float(best_match[-1]), 3)\n",
    "            intensity = int(distance_scale * distance)\n",
    "            yield _span_template.format('fan', \n",
    "                                        match_from, \n",
    "                                        'script', \n",
    "                                        match_to, \n",
    "                                        intensity, \n",
    "                                        distance, \n",
    "                                        str(w))\n",
    "\n",
    "        else:\n",
    "            yield str(w) + ' '\n",
    "\n",
    "def render_parallel_html_browser(matches, script, fan_filename_base):\n",
    "    matches = query_matches(matches, fan_filename_base)\n",
    "    fan_work = load_fan_work(fan_filename_base)\n",
    "    fan_filename_html = fan_filename_base.replace('.txt', '.html')\n",
    "    \n",
    "    script_html = ''.join(script_match_html(matches, script))\n",
    "    fan_html = ''.join(fan_match_html(matches, fan_work))\n",
    "    html = html_wrapper.format(\n",
    "        fan_filename_base,\n",
    "        script_html.replace('\\n', '<br/>'),\n",
    "        fan_html.replace('\\n', '<br/>')\n",
    "    )\n",
    "    \n",
    "    with open(browser_directory + fan_filename_html, \n",
    "              'w', encoding='utf-8') as op:\n",
    "        op.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('7382338.txt', 2356), ('5660062.txt', 1456), ('5698945.txt', 1394), ('6396253.txt', 1130), ('5769406.txt', 861), ('6486928.txt', 841), ('5894128.txt', 832), ('5695981.txt', 830), ('6820258.txt', 780), ('5738035.txt', 771), ('6480097.txt', 649), ('6740008.txt', 615), ('5765002.txt', 604), ('8242133.txt', 562), ('5608165.txt', 553), ('6487681.txt', 516), ('6165466.txt', 498), ('6876964.txt', 464), ('8142448.txt', 458), ('6410248.txt', 454), ('6100877.txt', 451), ('6831736.txt', 450), ('6799831.txt', 429), ('5629045.txt', 421), ('5483021.txt', 384), ('5453528.txt', 382), ('5704957.txt', 381), ('5594569.txt', 370), ('6111699.txt', 366), ('7568425.txt', 366), ('5989575.txt', 363), ('5789281.txt', 362), ('5867329.txt', 356), ('7570705.txt', 356), ('5709586.txt', 352), ('7329643.txt', 348), ('7571068.txt', 344), ('5629843.txt', 339), ('7087519.txt', 336), ('9254795.txt', 336), ('5520158.txt', 334), ('6864859.txt', 327), ('5871907.txt', 325), ('7570435.txt', 322), ('6572161.txt', 321), ('6053959.txt', 320), ('6984937.txt', 319), ('5873950.txt', 317), ('6101911.txt', 316), ('7442263.txt', 316)]\n",
      "23\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "matches = load_matches(match_filename)\n",
    "# match_map = contig_match_map_merged_no_overlap(matches, 6)\n",
    "match_map = contig_match_map_merged(matches, 6)\n",
    "script = load_markup_script(script_filename)[1:]\n",
    "\n",
    "top_reusers = Counter({fn: len(m) for fn, m in match_map.items()})\n",
    "top_reusers = top_reusers.most_common(50)\n",
    "print(top_reusers)\n",
    "top_reusers_2 = [('7382338.txt', 1672), ('5660062.txt', 970), ('6396253.txt', 803), \n",
    "               ('5695981.txt', 716), ('5765002.txt', 511), ('5894128.txt', 367), \n",
    "               ('5608165.txt', 366), ('8142448.txt', 344), ('8242133.txt', 344), \n",
    "               ('6487681.txt', 322), ('7568425.txt', 294), ('6876964.txt', 291), \n",
    "               ('5709586.txt', 276), ('7570435.txt', 261), ('5926093.txt', 259), \n",
    "               ('7570705.txt', 255), ('5663341.txt', 241), ('5989575.txt', 214), \n",
    "               ('6101911.txt', 205), ('5668453.txt', 200), ('6864859.txt', 196), \n",
    "               ('9249833.txt', 194), ('5620315.txt', 192), ('8574436.txt', 192), \n",
    "               ('6487381.txt', 189), ('5789281.txt', 186), ('6740008.txt', 186), \n",
    "               ('5809261.txt', 184), ('7364140.txt', 180), ('5738035.txt', 179), \n",
    "               ('5504096.txt', 174), ('7329643.txt', 172), ('5871907.txt', 170), \n",
    "               ('6359890.txt', 168), ('6572161.txt', 162), ('6165466.txt', 160), \n",
    "               ('6585115.txt', 159), ('9254591.txt', 159), ('7571068.txt', 157), \n",
    "               ('6143874.txt', 155), ('6726715.txt', 155), ('6472714.txt', 154), \n",
    "               ('7442263.txt', 151), ('5528261.txt', 150), ('6939529.txt', 149), \n",
    "               ('5827186.txt', 148), ('6886216.txt', 140), ('6748732.txt', 139), \n",
    "               ('6989956.txt', 136), ('5663299.txt', 134)]\n",
    "print(len({f for f, c in top_reusers} - {f for f, c in top_reusers_2}))\n",
    "print(len({f for f, c in top_reusers_2} - {f for f, c in top_reusers}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for fn, count in top_reusers:\n",
    "    render_parallel_html_browser(matches, script, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
