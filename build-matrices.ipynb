{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import itertools\n",
    "import collections\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "sp = spacy.load('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_file = 'force-awakens-markup.txt'\n",
    "match10g_file = 'match-20k-10gram-20170406.csv'\n",
    "match6g_file = 'match-6gram-20170614.csv'\n",
    "\n",
    "script = load_markup_script(script_file)\n",
    "script_header = script[0]\n",
    "script = script[1:]\n",
    "with open(match10g_file, encoding='utf-8') as ip:\n",
    "    match10g = list(csv.reader(ip))\n",
    "with open(match6g_file, encoding='utf-8') as ip:\n",
    "    match6g = list(csv.reader(ip))\n",
    "match10g_header = match10g[0]\n",
    "match10g = match10g[1:]\n",
    "match10g.sort()\n",
    "match6g_header = match6g[0]\n",
    "match6g = match6g[1:]\n",
    "for m in match6g:\n",
    "    m[0] = os.path.split(m[0])[-1]\n",
    "match6g.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_markup_script(filename,\n",
    "                        _line_rex=re.compile('LINE<<(?P<line>[^>]*)>>'),\n",
    "                        _scene_rex=re.compile('SCENE_NUMBER<<(?P<scene>[^>]*)>>'),\n",
    "                        _char_rex=re.compile('CHARACTER_NAME<<(?P<character>[^>]*)>>')):\n",
    "    with open(filename, encoding='utf-8') as ip:\n",
    "        current_scene = None\n",
    "        current_char = None\n",
    "        current_line = None\n",
    "        rows = [['WORD', 'SPACY_ORTH_ID', 'LOWERCASE', 'LOWERCASE_ORTH_ID', 'SCENE', 'CHARACTER']]\n",
    "        for i, line in enumerate(ip):\n",
    "            if _scene_rex.search(line):\n",
    "                current_scene = int(_scene_rex.search(line).group('scene'))\n",
    "            elif _char_rex.search(line):\n",
    "                current_char = _char_rex.search(line).group('character')\n",
    "            elif _line_rex.search(line):\n",
    "                tokens = sp(_line_rex.search(line).group('line'))\n",
    "                for t in tokens:\n",
    "                    # original Spacy lexeme object can be recreated using\n",
    "                    #     spacy.lexeme.Lexeme(sp.vocab, t.orth)\n",
    "                    # where `sp = spacy.load('en')`\n",
    "                    row = [t.orth_, t.orth, t.lower_, t.lower, current_scene, current_char]\n",
    "                    rows.append(row)\n",
    "    return rows\n",
    "\n",
    "def group_works(matches):\n",
    "    return {k: sorted(v, key=lambda x: int(x[1])) \n",
    "            for k, v in \n",
    "            itertools.groupby(matches, key=lambda x: x[0])}\n",
    "\n",
    "def group_contig(matches):\n",
    "    groups = group_works(matches)\n",
    "    return {k: find_contig(v) for k, v in groups.items()}\n",
    "\n",
    "def window_contig(matches):\n",
    "    groups = group_contig(matches)\n",
    "    new_groups = {}\n",
    "    for k, v in groups.items():\n",
    "        new_v = []\n",
    "        for cix, contig in enumerate(v):\n",
    "            contig_joined = [contig[i:i + 6] for i in range(len(contig) - 5)]\n",
    "            for cj in contig_joined:\n",
    "                new_v.append(wordrows_to_ngramrow(cj))\n",
    "        new_groups[k] = new_v\n",
    "    return new_groups\n",
    "\n",
    "def wordrows_to_ngramrow(rows):\n",
    "    fan_words = ' '.join(r[2] for r in rows)\n",
    "    script_words = ' '.join(script[int(r[4])][0] for r in rows)\n",
    "    row = rows[0].copy()\n",
    "    row[2] = fan_words\n",
    "    row[5] = script_words\n",
    "    return row\n",
    "\n",
    "def inspect_dict(d, n=0):\n",
    "    return next(itertools.islice(iter(d.items()), n, n + 1))\n",
    "\n",
    "def find_contig(matches):\n",
    "    contig = []\n",
    "    last = -2\n",
    "    for r in matches:\n",
    "        ix = int(r[1])\n",
    "        if int(ix) != last + 1:\n",
    "            contig.append([r])\n",
    "        else:\n",
    "            contig[-1].append(r)\n",
    "        last = ix\n",
    "    return contig\n",
    "\n",
    "def build_matrix(work_matches, threshold=None):\n",
    "    row_names = sorted(work_matches.keys(), \n",
    "                       key=lambda x: int(os.path.splitext(x)[0]))\n",
    "    row_index = {n: i for i, n in enumerate(row_names)}\n",
    "    col_index = {m[4]: m[3] \n",
    "                 for matches in work_matches.values() \n",
    "                 for m in matches}\n",
    "    col_names = sorted(col_index, key=col_index.get)\n",
    "    col_dense_index = {n: i for i, n in enumerate(col_names)}\n",
    "    \n",
    "    col_names = ['FILENAME'] + col_names\n",
    "    col_names = [re.sub('\\s+', ' ', n) for n in col_names]\n",
    "    \n",
    "    col_n = max(col_dense_index.values()) + 1\n",
    "    \n",
    "    matrix = [col_names]\n",
    "    for rn in row_names:\n",
    "        row = [0] * col_n\n",
    "        row[0] = rn\n",
    "        for m in work_matches[rn]:\n",
    "            if threshold is None or m[-1] < threshold:\n",
    "                row[col_dense_index[m[4]]] = 1\n",
    "        matrix.append(row)\n",
    "    \n",
    "    rowsum = matrix[1][1:]\n",
    "    for r in matrix[1:]:\n",
    "        rowsum = [a + b for a, b in zip(rowsum, r[1:])]    \n",
    "    rowsum = ['Total'] + rowsum\n",
    "    \n",
    "    matrix.append(rowsum)\n",
    "    discard = [t != 'Total' and t == 0 for t in rowsum]\n",
    "    for r in matrix:\n",
    "        r[:] = [cell for cell, dis in zip(r, discard) if not dis]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "match10g_works = group_works(match10g)\n",
    "for v in match10g_works.values():\n",
    "    for i, vv in enumerate(v):\n",
    "        v[i] = vv[0:5] + vv[6:]\n",
    "        vv = v[i]\n",
    "        vv[1] = int(vv[1])\n",
    "        vv[3] = int(vv[3])\n",
    "        vv[5] = float(vv[5])\n",
    "        vv[6] = int(vv[6])\n",
    "        vv[7] = float(vv[7])\n",
    "match6g_works = window_contig(match6g)\n",
    "for v in match6g_works.values():\n",
    "    for i, vv in enumerate(v):\n",
    "        v[i] = vv[0:3] + vv[4:6] + vv[9:]\n",
    "        vv = v[i]\n",
    "        vv[1] = int(vv[1])\n",
    "        vv[3] = int(vv[3])\n",
    "        vv[5] = float(vv[5])\n",
    "        vv[6] = int(vv[6])\n",
    "        vv[7] = float(vv[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_10gram = build_matrix(match10g_works)\n",
    "with open('match-10gram-matrix-thresh-none.csv', 'w', encoding='utf-8') as op:\n",
    "    csv.writer(op).writerows(mat_10gram)\n",
    "mat_10gram = build_matrix(match10g_works, threshold=0.2)\n",
    "with open('match-10gram-matrix-thresh-0.2.csv', 'w', encoding='utf-8') as op:\n",
    "    csv.writer(op).writerows(mat_10gram)\n",
    "mat_6gram = build_matrix(match6g_works)\n",
    "with open('match-6gram-matrix-thresh-none.csv', 'w', encoding='utf-8') as op:\n",
    "    csv.writer(op).writerows(mat_6gram)\n",
    "mat_6gram = build_matrix(match6g_works, threshold=0.05)\n",
    "with open('match-6gram-matrix-thresh-0.05.csv', 'w', encoding='utf-8') as op:\n",
    "    csv.writer(op).writerows(mat_6gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
